{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Conv2D, MaxPooling2D, UpSampling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# import keras\n",
    "# from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Flatten, Reshape, Conv2DTranspose\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.optimizers import Adam\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_dir= \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "# train_dir_nhd = \"data/train/not_hot_dog\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 508 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(rescale = 1.0/255.0, zoom_range = 0.2)\n",
    "\n",
    "batch_size = 32\n",
    "training_data = data_generator.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (64, 64),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'binary',\n",
    "                                                  shuffle = True)\n",
    "testing_data = data_generator.flow_from_directory(directory = test_dir,\n",
    "                                                  target_size = (64, 64),\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = 'binary',\n",
    "                                                 shuffle = True)\n",
    "\n",
    "# Validation set must be done manually, unless using image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "0: \"hot_dog\",\n",
    "1: \"not_hot_dog\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ehsieh/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=training_data.image_shape))\n",
    "# model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#               optimizer=tf.keras.optimizers.Adam(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=training_data.image_shape))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', input_shape = training_data.image_shape))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 2.1316 - acc: 0.5030\n",
      "Epoch 2/16\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.6959 - acc: 0.5896\n",
      "Epoch 3/16\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.6027 - acc: 0.6713\n",
      "Epoch 4/16\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 0.5570 - acc: 0.7333\n",
      "Epoch 5/16\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.5251 - acc: 0.7421\n",
      "Epoch 6/16\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.4501 - acc: 0.7923\n",
      "Epoch 7/16\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.4015 - acc: 0.8258\n",
      "Epoch 8/16\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.3590 - acc: 0.8563\n",
      "Epoch 9/16\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.3119 - acc: 0.8789\n",
      "Epoch 10/16\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.2718 - acc: 0.8976\n",
      "Epoch 11/16\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 0.2550 - acc: 0.8967\n",
      "Epoch 12/16\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.2033 - acc: 0.9262\n",
      "Epoch 13/16\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.2014 - acc: 0.9232\n",
      "Epoch 14/16\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.1991 - acc: 0.9213\n",
      "Epoch 15/16\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 0.1455 - acc: 0.9478\n",
      "Epoch 16/16\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 0.1533 - acc: 0.9508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63e4d3da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 16\n",
    "\n",
    "model.fit(training_data,\n",
    "          steps_per_epoch = 32,\n",
    "          epochs=n_epochs,\n",
    "          verbose=1)\n",
    "\n",
    "# history = model.fit(training_data,\n",
    "# steps_per_epoch=16,\n",
    "# epochs=16,\n",
    "# verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam Logs:\n",
    "# Conv2D: 8, Dense:256, Acc:94\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x63e4d3da0>\n"
     ]
    }
   ],
   "source": [
    "# plotting accuracy and validation accuracy\n",
    "accuracy = model.history\n",
    "\n",
    "# print(accuracy)\n",
    "\n",
    "# plt.plot(range(len(accuracy)), accuracy, label = 'accuracy')\n",
    "# plt.plot(range(len(val_acc)), val_acc, label = 'validation')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.03415351, 0.00923362, 0.0071479 ],\n",
       "          [0.04571113, 0.01636012, 0.00392157],\n",
       "          [0.03921569, 0.01960784, 0.00392157],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.03415351, 0.00923362, 0.0071479 ],\n",
       "          [0.04571113, 0.01636012, 0.00392157],\n",
       "          [0.03921569, 0.01960784, 0.00392157],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.03148327, 0.00656338, 0.00447766],\n",
       "          [0.04424615, 0.0153986 , 0.00270832],\n",
       "          [0.03823818, 0.0215603 , 0.00440904],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.33206886, 0.40077388, 0.3574815 ],\n",
       "          [0.33979517, 0.410872  , 0.36725602],\n",
       "          [0.3533869 , 0.43589497, 0.39071935],\n",
       "          ...,\n",
       "          [0.3234833 , 0.41571772, 0.37415344],\n",
       "          [0.31804812, 0.39870068, 0.36239758],\n",
       "          [0.30166367, 0.38009506, 0.34480092]],\n",
       " \n",
       "         [[0.32365438, 0.3942426 , 0.3471838 ],\n",
       "          [0.33602875, 0.40931237, 0.36225355],\n",
       "          [0.34836718, 0.4346417 , 0.38758287],\n",
       "          ...,\n",
       "          [0.31075975, 0.4048774 , 0.353897  ],\n",
       "          [0.31246337, 0.39341903, 0.35560063],\n",
       "          [0.3104564 , 0.38888776, 0.35359365]],\n",
       " \n",
       "         [[0.32365438, 0.3942426 , 0.3471838 ],\n",
       "          [0.33602875, 0.40931237, 0.36225355],\n",
       "          [0.34836718, 0.4346417 , 0.38758287],\n",
       "          ...,\n",
       "          [0.31075975, 0.4048774 , 0.353897  ],\n",
       "          [0.31246337, 0.39341903, 0.35560063],\n",
       "          [0.3104564 , 0.38888776, 0.35359365]]],\n",
       " \n",
       " \n",
       "        [[[0.20784315, 0.23482056, 0.34878284],\n",
       "          [0.20784315, 0.23482056, 0.34878284],\n",
       "          [0.20784315, 0.23482056, 0.34878284],\n",
       "          ...,\n",
       "          [0.12122797, 0.28258556, 0.5247469 ],\n",
       "          [0.1217908 , 0.28328547, 0.5254756 ],\n",
       "          [0.1217908 , 0.28328547, 0.5254756 ]],\n",
       " \n",
       "         [[0.20761365, 0.2194931 , 0.34083223],\n",
       "          [0.20761365, 0.2194931 , 0.34083223],\n",
       "          [0.20761365, 0.2194931 , 0.34083223],\n",
       "          ...,\n",
       "          [0.25752932, 0.441994  , 0.6542522 ],\n",
       "          [0.26109844, 0.4463302 , 0.6595866 ],\n",
       "          [0.26109844, 0.4463302 , 0.6595866 ]],\n",
       " \n",
       "         [[0.20088887, 0.21624182, 0.32985622],\n",
       "          [0.20088887, 0.21624182, 0.32985622],\n",
       "          [0.20088887, 0.21624182, 0.32985622],\n",
       "          ...,\n",
       "          [0.44840774, 0.6606498 , 0.9190755 ],\n",
       "          [0.45944473, 0.6741311 , 0.93487626],\n",
       "          [0.45944473, 0.6741311 , 0.93487626]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.17223758, 0.10227226, 0.15696657],\n",
       "          [0.17223758, 0.10227226, 0.15696657],\n",
       "          [0.17223758, 0.10227226, 0.15696657],\n",
       "          ...,\n",
       "          [0.58312   , 0.5871913 , 0.81118464],\n",
       "          [0.58358705, 0.58730096, 0.81083035],\n",
       "          [0.58358705, 0.58730096, 0.81083035]],\n",
       " \n",
       "         [[0.17636313, 0.10577489, 0.15304865],\n",
       "          [0.17636313, 0.10577489, 0.15304865],\n",
       "          [0.17636313, 0.10577489, 0.15304865],\n",
       "          ...,\n",
       "          [0.5992095 , 0.6036043 , 0.8272627 ],\n",
       "          [0.59957016, 0.6034917 , 0.8270211 ],\n",
       "          [0.59957016, 0.6034917 , 0.8270211 ]],\n",
       " \n",
       "         [[0.1764706 , 0.11350328, 0.15294118],\n",
       "          [0.1764706 , 0.11350328, 0.15294118],\n",
       "          [0.1764706 , 0.11350328, 0.15294118],\n",
       "          ...,\n",
       "          [0.61846346, 0.63071394, 0.8466258 ],\n",
       "          [0.61905235, 0.63059485, 0.8465033 ],\n",
       "          [0.61905235, 0.63059485, 0.8465033 ]]],\n",
       " \n",
       " \n",
       "        [[[0.0359499 , 0.08206586, 0.11438128],\n",
       "          [0.10481879, 0.17605756, 0.20541999],\n",
       "          [0.33182475, 0.3981697 , 0.38592237],\n",
       "          ...,\n",
       "          [0.17201318, 0.24367312, 0.34786263],\n",
       "          [0.18292923, 0.24567433, 0.34763512],\n",
       "          [0.14759968, 0.20880833, 0.30001393]],\n",
       " \n",
       "         [[0.0359499 , 0.08206586, 0.11438128],\n",
       "          [0.10481879, 0.17605756, 0.20541999],\n",
       "          [0.33182475, 0.3981697 , 0.38592237],\n",
       "          ...,\n",
       "          [0.17201318, 0.24367312, 0.34786263],\n",
       "          [0.18292923, 0.24567433, 0.34763512],\n",
       "          [0.14759968, 0.20880833, 0.30001393]],\n",
       " \n",
       "         [[0.0359499 , 0.08206586, 0.11438128],\n",
       "          [0.10481879, 0.17605756, 0.20541999],\n",
       "          [0.33182475, 0.3981697 , 0.38592237],\n",
       "          ...,\n",
       "          [0.17201318, 0.24367312, 0.34786263],\n",
       "          [0.18292923, 0.24567433, 0.34763512],\n",
       "          [0.14759968, 0.20880833, 0.30001393]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.00508303, 0.01292617, 0.0090046 ],\n",
       "          [0.00291651, 0.01075965, 0.00683808],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          ...,\n",
       "          [0.00445743, 0.02406527, 0.008379  ],\n",
       "          [0.00322931, 0.02445181, 0.01522416],\n",
       "          [0.00784314, 0.0298361 , 0.03905483]],\n",
       " \n",
       "         [[0.00508303, 0.01292617, 0.0090046 ],\n",
       "          [0.00291651, 0.01075965, 0.00683808],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          ...,\n",
       "          [0.00445743, 0.02406527, 0.008379  ],\n",
       "          [0.00322931, 0.02445181, 0.01522416],\n",
       "          [0.00784314, 0.0298361 , 0.03905483]],\n",
       " \n",
       "         [[0.00508303, 0.01292617, 0.0090046 ],\n",
       "          [0.00291651, 0.01075965, 0.00683808],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          ...,\n",
       "          [0.00445743, 0.02406527, 0.008379  ],\n",
       "          [0.00322931, 0.02445181, 0.01522416],\n",
       "          [0.00784314, 0.0298361 , 0.03905483]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.36939728, 0.13277288, 0.06792904],\n",
       "          [0.40390334, 0.15875003, 0.09638631],\n",
       "          [0.4344051 , 0.18678862, 0.11826308],\n",
       "          ...,\n",
       "          [0.3058364 , 0.11840997, 0.06500872],\n",
       "          [0.35057768, 0.23162062, 0.15398999],\n",
       "          [0.498943  , 0.4186773 , 0.30199748]],\n",
       " \n",
       "         [[0.3045784 , 0.10280047, 0.03756464],\n",
       "          [0.32987088, 0.12336453, 0.05629555],\n",
       "          [0.35351434, 0.14565592, 0.07460856],\n",
       "          ...,\n",
       "          [0.28299004, 0.13891159, 0.09416798],\n",
       "          [0.34377417, 0.27471554, 0.21219102],\n",
       "          [0.40727615, 0.3764216 , 0.2841838 ]],\n",
       " \n",
       "         [[0.2518842 , 0.08963573, 0.0324914 ],\n",
       "          [0.26929432, 0.10829633, 0.04752273],\n",
       "          [0.27191406, 0.10772582, 0.05173993],\n",
       "          ...,\n",
       "          [0.2897593 , 0.22218522, 0.20070723],\n",
       "          [0.33063242, 0.31812355, 0.29670757],\n",
       "          [0.3639765 , 0.36972746, 0.33570233]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.26840436, 0.18109044, 0.05716774],\n",
       "          [0.1599194 , 0.09498198, 0.01982709],\n",
       "          [0.1629635 , 0.09530775, 0.01905875],\n",
       "          ...,\n",
       "          [0.9028823 , 0.63335407, 0.20871091],\n",
       "          [0.92005205, 0.62300235, 0.2082711 ],\n",
       "          [0.9464156 , 0.65671843, 0.22934128]],\n",
       " \n",
       "         [[0.48278072, 0.3571624 , 0.1778525 ],\n",
       "          [0.35599884, 0.24243867, 0.09127831],\n",
       "          [0.27624822, 0.16987208, 0.04904265],\n",
       "          ...,\n",
       "          [0.9781715 , 0.8453152 , 0.46200755],\n",
       "          [0.98612076, 0.8524438 , 0.4596462 ],\n",
       "          [0.9637451 , 0.7357073 , 0.34886596]],\n",
       " \n",
       "         [[0.75357   , 0.6295597 , 0.377706  ],\n",
       "          [0.53626174, 0.39505243, 0.17218198],\n",
       "          [0.41461062, 0.2765991 , 0.10532563],\n",
       "          ...,\n",
       "          [0.95922893, 0.8294824 , 0.47134387],\n",
       "          [0.9751562 , 0.8525692 , 0.48542106],\n",
       "          [0.9769378 , 0.80413556, 0.42718646]]],\n",
       " \n",
       " \n",
       "        [[[0.89019614, 0.90196085, 0.8745099 ],\n",
       "          [0.89019614, 0.90196085, 0.8745099 ],\n",
       "          [0.89019614, 0.90196085, 0.8745099 ],\n",
       "          ...,\n",
       "          [0.98823535, 0.9960785 , 0.94117653],\n",
       "          [0.98823535, 0.9960785 , 0.94117653],\n",
       "          [0.98823535, 0.9960785 , 0.94117653]],\n",
       " \n",
       "         [[0.89019614, 0.90196085, 0.8745099 ],\n",
       "          [0.89019614, 0.90196085, 0.8745099 ],\n",
       "          [0.89019614, 0.90196085, 0.8745099 ],\n",
       "          ...,\n",
       "          [0.98823535, 0.9960785 , 0.94117653],\n",
       "          [0.98823535, 0.9960785 , 0.94117653],\n",
       "          [0.98823535, 0.9960785 , 0.94117653]],\n",
       " \n",
       "         [[0.89019614, 0.90196085, 0.8745099 ],\n",
       "          [0.89019614, 0.90196085, 0.8745099 ],\n",
       "          [0.89019614, 0.90196085, 0.8745099 ],\n",
       "          ...,\n",
       "          [0.98823535, 0.9960785 , 0.94117653],\n",
       "          [0.98823535, 0.9960785 , 0.94117653],\n",
       "          [0.98823535, 0.9960785 , 0.94117653]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.78823537, 0.7725491 , 0.627451  ],\n",
       "          [0.78823537, 0.7725491 , 0.627451  ],\n",
       "          [0.78823537, 0.7725491 , 0.627451  ],\n",
       "          ...,\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ],\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ],\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ]],\n",
       " \n",
       "         [[0.78823537, 0.7725491 , 0.627451  ],\n",
       "          [0.78823537, 0.7725491 , 0.627451  ],\n",
       "          [0.78823537, 0.7725491 , 0.627451  ],\n",
       "          ...,\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ],\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ],\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ]],\n",
       " \n",
       "         [[0.78823537, 0.7725491 , 0.627451  ],\n",
       "          [0.78823537, 0.7725491 , 0.627451  ],\n",
       "          [0.78823537, 0.7725491 , 0.627451  ],\n",
       "          ...,\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ],\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ],\n",
       "          [0.9490197 , 0.9294118 , 0.7803922 ]]],\n",
       " \n",
       " \n",
       "        [[[0.86274517, 0.9294118 , 0.9921569 ],\n",
       "          [0.86988163, 0.93833244, 0.99572515],\n",
       "          [0.8673196 , 0.9360558 , 0.9962961 ],\n",
       "          ...,\n",
       "          [0.4003129 , 0.43318886, 0.493731  ],\n",
       "          [0.80776125, 0.8844366 , 0.9688732 ],\n",
       "          [0.80392164, 0.89019614, 0.9803922 ]],\n",
       " \n",
       "         [[0.86274517, 0.9294118 , 0.9921569 ],\n",
       "          [0.86988163, 0.93833244, 0.99572515],\n",
       "          [0.8673196 , 0.9360558 , 0.9962961 ],\n",
       "          ...,\n",
       "          [0.4003129 , 0.43318886, 0.493731  ],\n",
       "          [0.80776125, 0.8844366 , 0.9688732 ],\n",
       "          [0.80392164, 0.89019614, 0.9803922 ]],\n",
       " \n",
       "         [[0.86274517, 0.9294118 , 0.9921569 ],\n",
       "          [0.86988163, 0.93833244, 0.99572515],\n",
       "          [0.8673196 , 0.9360558 , 0.9962961 ],\n",
       "          ...,\n",
       "          [0.4003129 , 0.43318886, 0.493731  ],\n",
       "          [0.80776125, 0.8844366 , 0.9688732 ],\n",
       "          [0.80392164, 0.89019614, 0.9803922 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.7372549 , 0.7019608 , 0.63529414],\n",
       "          [0.7426073 , 0.7090973 , 0.6495672 ],\n",
       "          [0.7416117 , 0.7157951 , 0.65370286],\n",
       "          ...,\n",
       "          [0.7800693 , 0.8976626 , 0.9921031 ],\n",
       "          [0.8419545 , 0.96352315, 0.9980802 ],\n",
       "          [0.87843144, 1.        , 1.        ]],\n",
       " \n",
       "         [[0.7372549 , 0.7019608 , 0.63529414],\n",
       "          [0.7426073 , 0.7090973 , 0.6495672 ],\n",
       "          [0.7416117 , 0.7157951 , 0.65370286],\n",
       "          ...,\n",
       "          [0.7800693 , 0.8976626 , 0.9921031 ],\n",
       "          [0.8419545 , 0.96352315, 0.9980802 ],\n",
       "          [0.87843144, 1.        , 1.        ]],\n",
       " \n",
       "         [[0.7372549 , 0.7019608 , 0.63529414],\n",
       "          [0.7426073 , 0.7090973 , 0.6495672 ],\n",
       "          [0.7416117 , 0.7157951 , 0.65370286],\n",
       "          ...,\n",
       "          [0.7800693 , 0.8976626 , 0.9921031 ],\n",
       "          [0.8419545 , 0.96352315, 0.9980802 ],\n",
       "          [0.87843144, 1.        , 1.        ]]]], dtype=float32),\n",
       " array([1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = testing_data[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(test_image[:, :, 0]) \n",
    "axes[0].set_title('Original image')\n",
    "axes[1].imshow(output_upsampled[:, :, 0])\n",
    "axes[1].set_title('Reconstructed image')\n",
    "fig.suptitle(f'Original and upsampled input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
